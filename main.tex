\documentclass[12pt,oneside]{report}

% ---------- Packages ----------
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{times}
\usepackage{mathptmx}
\usepackage{setspace}
\usepackage{geometry}
\geometry{letterpaper, margin=1in}
\usepackage{graphicx}
\graphicspath{{figures/}}
\usepackage{caption}
\usepackage{subcaption}
% ML conference style captions
\captionsetup{font=small, labelfont=bf, skip=8pt}
\captionsetup[sub]{font=footnotesize, labelfont=bf}
\usepackage{booktabs}
\usepackage{amsmath, amssymb}
\usepackage[hidelinks]{hyperref}
\usepackage[nameinlink,capitalise]{cleveref}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{titlesec}
\usepackage{xparse}
\usepackage{mysymbols}

% Minimal approach - let LaTeX handle TOC normally
\usepackage{csquotes}
\usepackage[style=numeric-comp,natbib=true,sorting=none]{biblatex}


\NewDocumentCommand{\scsurname}{m m o}{%
  #1~\textsc{#2}%
  \IfValueT{#3}{\space #3}%
}

\addbibresource{references.bib}

\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{2}
\setstretch{1.15}

% Custom chapter formatting - remove "Chapter" prefix and newlines
\titleformat{\chapter}[hang]
{\normalfont\Large\bfseries}{\thechapter}{1em}{}
\titlespacing*{\chapter}{0pt}{0pt}{15pt}

% Tighter section spacing
\titlespacing*{\section}{0pt}{12pt plus 2pt minus 2pt}{8pt plus 2pt minus 2pt}
\titlespacing*{\subsection}{0pt}{10pt plus 2pt minus 2pt}{6pt plus 1pt minus 1pt}

% ML conference style paragraph formatting
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}

% ---------- Convenience ----------
\newcommand{\todo}[1]{\textcolor{red}{TODO: #1}}

% ---------- Title Info ----------
\newcommand{\proposaltitle}{Deep Learning for Scalable Sensorimotor Brain-Computer Interfaces}
\newcommand{\authorname}{Joel Ye}
\newcommand{\department}{
  Neural Computation, Neuroscience Institute \\
  Machine Learning Department, School of Computer Science \\
}
\newcommand{\university}{Carnegie Mellon University \\ Pittsburgh, PA}
\newcommand{\proposaldate}{July 30, 2025}

\newcommand{\committee}{%
  \scsurname{Robert}{Gaunt}[({co-chair})]\\[0.15\baselineskip]
  \scsurname{Leila}{Wehbe}[({co-chair})]\\[0.15\baselineskip]
  \scsurname{Jennifer}{Collinger}\\[0.15\baselineskip]
  \scsurname{Aran}{Nayebi}\\[0.15\baselineskip]
  \scsurname{Chethan}{Pandarinath}[({Emory University})]%
}

% ---------- Document ----------
\begin{document}

% --- title page ---
\begin{titlepage}
\setlength{\parindent}{0pt}
\centering

% top breathing room
\vspace*{\stretch{1}}

% Title block
{\LARGE\bfseries \proposaltitle\par}
\vspace{0.6\baselineskip}
{\Large \authorname\par}

\vspace{1.5\baselineskip}
{\large PhD Thesis Proposal\par}
{\small \proposaldate\par}

\vspace{1.2\baselineskip}
{\normalsize
\begin{minipage}{0.9\textwidth}\centering
\department
\university
\end{minipage}\par}

% middle breathing room (larger to push committee lower)
\vspace*{\stretch{2}}

% Committee block
{\large\bfseries Thesis Committee:\par}
\vspace{0.4\baselineskip}
{\normalsize
\begin{minipage}{0.7\textwidth}\centering
\setlength{\parskip}{0pt}%
\committee
\end{minipage}\par}

% bottom breathing room (largest to anchor footer)
\vspace*{\stretch{3}}

{\small\itshape
Submitted in partial fulfillment of the requirements for the Degree of Doctor of Philosophy\par}

\vspace*{\stretch{1}}
\end{titlepage}
\pagenumbering{arabic}

\section*{Abstract}
\addcontentsline{toc}{section}{Abstract}
The increasing ambition of neuroscience and neurotechnology both supplies and demands vast new quantities of neural data, which creates a critical need for methods that can operate effectively on neural data at scale.
This need could potentially be addressed by deep learning (DL).
Here, we assess this program for sensorimotor intracortical brain-computer interfaces (iBCI). iBCI systems have traditionally been built by collecting short datasets to relate a user’s neural activity with their bodily state. Although this approach can enable both motor control and sensory feedback in research settings, iBCI's real-world adoption will further depend on achieving high performance with exquisite reliability and convenience. In other words, iBCI systems must too, evolve to operate effectively on BCI data at real-world scales.
To this end, I present one completed study and two proposed projects that show how deep learning models can provide a platform for scaling BCI systems. Through this platform, I promote a view that BCI models can and should be built to reflect the BCI system's lifelong data collection.

% Therefore, this challenge might be best met with deep learning models that encapsulate the landscape of data accumulated throughout the BCI device's lifetime.
% Therefore, this challenge might be best met with deep learning models that encapsulate the landscape of data accumulated throughout the BCI device's lifetime.
% deep learning becomes an  provide a tractable platform with which to encapsulate this landscape.
% That is, by reframing the accumulation of BCI datasets throughout device lifetime not as standalone snapshots but as a landscape of related data,
%  reframe BCI data not as a collection of standalone datasets but as a store of related data accumulated throughout the BCI device's lifetime.
% I next introduce one result and two proposed works that build this case.

\textbf{Aim 1: Large scale pretraining improves modeling of intracortical motor datasets [in submission].}

The driver of deep learning’s efficacy across domains is its ability to leverage conserved statistical structure across datasets, primarily enabled by a stage of model preparation on large scale data called pretraining. Previous work has identified the requisite conserved structures across motor cortical datasets, and so we systematically measure the efficacy of deep neural network (DNN) pretraining on such datasets. We establish that DNN efficacy improves with neural data scale on both multi-subject and multi-behavior datasets. Yet, this scaling has diminishing returns as data in the downstream, target setting grows, rendering the scaling less impactful for long term BCI applications. We conclude that pretrained networks may accelerate initial BCI calibration speeds but will not fundamentally remove the need for continuous BCI data collection.

\textbf{Aim 2: Pretrained deep networks enable rapid and scaleable upper limb neuroprosthetic control [proposed].}

High degree of freedom control of a robotic arm and hand is possible with current iBCIs, but requires extensive daily recalibration and experimenter intervention. Based on successful deep network use in speech BCIs, we propose that an NDT-based controller (NDT3o) which accumulates calibration data across days can address both of these challenges. We will evaluate NDT3o for 7-degree of freedom neuroprosthetic arm and hand control in up to two human participants, aiming to demonstrate continuous high performance in functional tasks of robotic upper limb control. We further aim to demonstrate the model’s scalability by extending this control to additional degrees of freedom in the hand without changes to the model design.

\textbf{Aim 3: Modeling intracortical microstimulation for sensory BCIs [proposed].}

Sensory feedback is integral to native motor control, and can be provided in iBCIs through intracortical microstimulation (ICMS) of the somatosensory cortex. The sensory feedback provided by ICMS has been shown to improve BCI control, but our understanding of how ICMS accomplishes this through its modulation of ongoing neural activity is poor. Specifically, we lack a predictive model of the neural response to ICMS, which stunts the development of any sophisticated ICMS protocols. Towards this goal, we first introduce a method to recover spiking activity from artifacted recordings, and then taxonomize the sensory neural response to ICMS through DNN transfer learning experiments. In this taxonomy, we show that while deep networks largely generalize to temporal variety in stimulation patterns, they fail to generalize to new stimulation channels. These results inform the development of stimulation protocols to accurately map the neural response to ICMS.

% Table of contents
\tableofcontents

\cleardoublepage

% =========================
% Introduction
% =========================
\chapter{Introduction and Background}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.9\linewidth]{ch1_hydra.png}
  \caption{Models of neural data must robustly relate neural activity to certain variables of interest while accounting for the influence of numerous other factors that also modulate the same neural activity.}
  % \caption{The role of a computational model is to provide an interface to interact with the underlying domain data. A scalable model is one that provides a tractable strategy to encapsulate and query a growing variety of data.}
  \label{fig:hydra}
\end{figure}

Today, neuroscientists seek to study the brain in natural, dynamic environments, and neurotechnology companies are similarly racing to produce a device that will work robustly in the real world.
In this increasing scope, a great variety of factors can affect the neural data that BCI devices collect, and consequently, the performance of the models built on that data. In the best cases, we have some mechanistic account of these factors, such as in our characterization of the physical degradation at the neural-electrode interface~\citep{pandarinath_22_review,bjaanes2024quantifying}. In other cases, well-controlled experiments provide a strong descriptive characterization, as in the case of cognitive states~\citep{cowley2020slow,smoulder2024neural} and body posture~\citep{marino2024posture}. Most often, we lump the remaining factors in the catch-all term of ``context,'' as often arises in studying similar motor behaviors under variable task requirements~\citep{mender23ctx,ma2021ctx,downey2017object}. Designing BCI systems that perform at scale is thus daunting because it should require accounting for all of these known factors and presumably many more unknown ones.

Fortunately, progress in BCIs has rarely hinged on theoretical clarity. The first population vector decoders were enabled by the observation that motor neurons fired reliably according to cosine tuning curves~\citep{Georgopoulos1986}, not from a mechanistic understanding of why they did so. A caricatured workflow for mitigating the myriad impacts of the above factors is to collect data and use this data to update our models. A deeper understanding can support expectations of model robustness, but ultimately, we must design BCIs that recover gracefully when our understanding eventually fails. Likely, the rate of BCI progress will hinge on how quickly our methods can adapt to empirical failures as they arise.

To minimize the Sisyphean burden of this task, many domains faced with similar challenges have turned to deep neural networks, deprioritizing interpretable theories in favor of radical empiricism~\citep{wang2023scientific}. In this proposal, I aim to establish such a data-driven framework for thinking about sensorimotor BCIs, describing three ways in which we can use deep networks to relate and aggregate BCI datasets. To contextualize this work, I will introduce brain computer interfaces and deep learning’s application to BCIs in turn.

\section{Brain-computer interface models}
\label{sec:bci_models}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.95\linewidth]{ch1_loop_and_lifecycle.png}
  \caption{A) A sensorimotor BCI-enabled control loop. By recording neural activity from an implanted microelectrode array, this BCI can allow the user to control a robotic hand. When touch sensors on the hand contact a physical object, we can deliver stimulation pulses back to the brain to provide the user sensory feedback. B) Motor BCI models must be calibrated to relate neural activity at the implant interface with the user's intentions. Performance increases over an explicit calibration phase, which can be accelerated with learned priors, but will decline over time during free use of the system. This decline can be mitigated with varied recalibration methods.}
  \label{fig:bci_overview}
\end{figure}

A brain-computer interface (BCI) is a system that allows observation and control of neural activity. In the rehabilitative setting, for example, BCIs can record from motor cortex to predict movement intentions and can control sensory cortex to evoke sensations. Together, the premise of a sensorimotor BCI is that we might directly relate a user's neural activity with their sensorimotor experience, and thereby restore a degree of sensorimotor function to a paralyzed user~(\figref{fig:bci_overview}A).

Over the last two decades, a number of studies have demonstrated the efficacy of human BCIs based on implanted microelectrode arrays~\citep{Brandman17Review,pandarinath_22_review}.
With implants in motor cortex recording neuronal spiking activity, users have achieved control of digital cursors, robotic arms, and language and speech generation~\citep{collinger2013high,willett_23_speech,wairagkar25voice,Pandarinath2017Pointandclick}.
With stimulation of implants in somatosensory cortex, users perceive tactile sensations on their hand, which is valuable as an end in itself but can also be utilized functionally for more skillful motor control~\citep{flesher2016intracortical,graczyk2024clinical,flesher2021functional,ArmentaSalas2018}.
BCI algorithms research now unfolds on several axes, naturally including expanding BCI capabilities to new functional milestones~\citep{willsey2024real,wairagkar25voice}, but also making the existing repertoire reliably performant across users and time~\citep{hosman2023months,fan2023plugandplay}, and minimizing user burden for system adoption~\citep{pandarinath_22_review,card2025long}.

\textbf{Motor BCI challenges}: Motor innovations can be organized by evaluating impact to BCI performance over time~(\figref{fig:bci_overview}B). BCI models are initialized with a calibration protocol where experimenters collect by paired neural activity and motor intention labels by prompting the user to behave according to experimental cues. The gray arc shows how BCI performance will increase with this calibration period~\citep{makin_18_refh}, but then decline over time due to signal nonstationarities that render the calibration data less relevant~\citep{karpowicz2022stabilizing}. Performance gain from calibration can be accelerated with strong priors, and given that practical constraints often end calibration before performance saturation, such priors may improve attained performance. Next, preserving model performance over time is a major priority for real world convenience, as the worst case strategy of recalibrating models from scratch imposes substantial user burden. One strategy to achieve persistent performance is collect a large corpus of calibration data across multiple days. This strategy has been used to provide multiple months of continuous performance in speech BCIs and 2D cursor control BCIs~\citep{willett_23_speech,card2024accurate,sussillo_16_future,hosman2023months}. Performance can also be explicitly maintained by using minimal supervised recalibration or behavioral priors (Weak recalibration)~\citep{wilson_23_prit,fan2023plugandplay}.
Multi-day data modeling has also enabled stable reach and grasp performance in an electrocorticographic (ECoG) device~\citep{Natraj2025robot}, but has not yet been applied for high performance simultaneous multi-DoF upper limb control.

\textbf{Sensory BCI challenges}: In contrast, sensory BCIs currently struggle less in model stability and more in building precise models of evoked sensations to begin with. That is, while any given stimuli's evoked percept location and quality appear relatively stable over time~\citep{greenspon_25_stable}, how these features of the evoked sensations relate to electrode choice and stimulation parameters are difficult to predict~\citep{hughes2021perception}. The consequence is that sensory BCI capabilities are currently developed by collecting a library of responses to varied stimulation patterns and selecting a subset of relevant patterns for use in functional tasks. One promising framework to guide future stimulation design is the principle of biomimicry. Biomimetic ICMS asserts that stimulation should be designed to evoke neural responses resembling those of natural touch, rather than directly matching stimulation frequencies or amplitudes to physical parameters~\citep{bensmaia2023restoration}. However, this aspiration is hamstringed on both ends, as it is difficult both to observe the neural response to ICMS and to observe the neural response to natural touch in BCI participants who typically have impaired somatosensory pathways. Current demonstrations of biomimetic ICMS have compromised by matching coarse, subject-general features of natural touch and assuming the neural response to ICMS is proportional to either frequency or amplitude inputs~\citep{valle2025tactile,hobbs2025biomimetic,greenspon_25_stable}. Realizing biomimetic ICMS in higher fidelity through neural activity, and thereby presumably improving somatosensory BCI efficacy overall, will require addressing both these assumptions.


\section{Deep network models of BCI data}
\label{sec:deep_networks}

Modern deep learning organizes applications research by the data being modeled, the model architecture, and the optimization objective. We will take this approach to introduce deep networks in BCI.

\textbf{Data}:
The neural data recorded from our BCIs are multichannel voltage timeseries. Most traditionally, and in the majority of this proposal, this broadband voltage will first be filtered and thresholded to extract rapid, transient deflections, which mark putative spikes on a neuron nearby the recording electrode. A typical BCI dataset will include 100 to 200 electrode channels of data with dozens of high amplitude spiking waveforms, along with many more channels with neural “hash” where nondistinctive, noisy spiking waveforms dominate. Our motor datasets will also contain upper limb covariates, for example in the form of kinematics or electromyography that varies on the timescale of seconds. In non-human primate datasets, these behaviors generally derive from physical sensors, but as mentioned in~\secref{sec:bci_models}, a different strategy must be used to create human BCI datasets since human BCI users have impaired control of their native limb. Human BCI datasets instead assert a certain behavior and experimentally cue the user to attempt the behavior. This artificial association means that the behavior label is likely to be temporally warped and otherwise imprecise~\citep{merel2016neuroprosthetic} relative to the unobserved motor intention of the user.
%  We can also frame this process as a user labeling of the cued behavior data with their neural activity.
The electrical stimuli that we use in sensory datasets comprise trains of biphasic current-controlled pulses, where each individual pulse’s timing and amplitude can be varied. Perceptual reports to ICMS, to the extent discussed in this proposal, will be described in terms of binary detection or scalar ratings of intensity.

\textbf{Architecture}: The mainstays of broader deep learning architectures that have flourished in the last decade, including MLPs~\citep{Willsey2022HighVelocity}, convolutional neural networks (CNNs)~\citep{temmar2024artificial}, recurrent neural networks (RNNs)~\citep{pandarinath_18_lfads}, and Transformers~\citep{ye_21_ndt}, have all been applied to BCI data. Unlike in other domains, BCI has yet to reach consensus on the most performant architectures. This proposal presumes the view of the Bitter Lesson~\citep{sutton2019}, which states that performance differences across architecture may be minor relative to gains from increasing data scale. Adopting this view, we contrast here only the RNN, which many neuroscientists may have familiarity with, and the Transformer, which has empirically dominated the architectural landscape in machine learning (ML) domains, including even other timeseries domains like audio processing~\citep{radford2022whisper}. RNNs process timeseries data one timestep at a time, maintaining an internal state that evolves with the input data. An RNN provides an appealing interpretative lens for neural data, as its iterations describe the evolution of the neural dynamical system. The Transformer, in contrast, does not maintain a centralized state but instead learns the relationship between fragments of the data. Each of these fragments is called a token, and they could be for example the population activity vector at the start of an experimental trial, abstract metadata about the experiment, or the vertical velocity of a user’s arm.

\textbf{Objective}: This proposal focuses on predictive objectives, namely regression and classification. This will be true despite the resulting models may be used for qualitatively different functions. When the work’s objective is to model neural data in isolation, we say we are interested in the model’s representation learning. At other times, we say we are building decoders of neural data to predict behavior, or encoders of stimuli to predict neural activity. With the lens of deep networks in particular, these different terms all implementationally overlap, in that the underlying models are operating between one or two data modalities.

\textbf{Challenges}: BCI datasets feature a number of challenges that uniquely interact with deep learning. First, by experimental design, there is often a large component of the neural data that appears strongly connected to the covariate of interest, implying there is not an immediately clear role for nonlinear DNNs. For example, in the motor cortex, we can identify single neurons with firing activity that can be well characterized by a cosine tuning curve with two parameters, a preferred arm direction and depth of firing rate modulation to movement in that direction. To balance this simplicity, BCI datasets will often have nonstationarities~\citep{downey_18_stability,wimalasena2020unstable,perge2013intra}, as discussed in the introduction. New cognitive states, neurophysiological changes at the electrode interface, and BCI system hardware state can all introduce shifts in the observed activity. These externalities are difficult to directly observe, so we must build systems that are implicitly robust to these shifts so as to enable stable BCI performance~\citep{sussillo_16_future}.

\textbf{Foundation models}: A modern trend in deep learning applications research is to create a model that provides broadly competent performance across tasks in a field, at which point the model can be considered a ``foundation model''. Foundation models were most deservingly coined in the context of natural language processing (NLP)~\citep{bommasani2022opportunitiesrisksfoundationmodels}, where a large scale initial training phase (pretraining) across internet text created models that quickly dominated all mainstream benchmarks~\citep{brown2020languagemodelsfewshotlearners}.
Critically, model performance correlates reliably with the scale of pretraining, providing the impetus for many fields to also measure the empirical “scaling” of model performance with their own domain's data~\citep{kaplan2020scaling}.
The merit of this paradigm for neuroscience writ large is still under debate, but this has not deterred a number of different efforts to create these large models in BCI domains~\citep{dyer_richards_2025_bitter_lesson}. Aim 1 discusses precisely this effort for intracortical motor BCI data.

% \textbf{Deep learning as systems tools}: The practice of deep learning is distinguished from the broader machine learning discipline by its strong empiricist culture. Mantras on model behavior develop based on what has previously been effective, like focusing on data over models or focusing on broad task performance over single tasks~\citep{abnar2021exploringlimitslargescale}. One pertinent empirical view is that foundation models are at minimum a catalog of their training data, and can easily learn simple functions. The value of this capability is exemplified in text cleaning, a domain that systems researcher Christopher Ré describes as facing a death by a thousand cuts, where individual problems are not technically challenging but their breadth and non-enumerability frustrate systematic solutions. Remarkably, early language models (GPT3) provided a simple solution to sanitizing human text entry and documents for errant values, outperforming rules-based agglomerations that received years of investment. Similarly, neural data appears locally linear in any given context, and the neural population activity may in fact be neatly organized so that certain aforementioned nonstationarities may simply not degrade existing models. It would be foolhardy to expect this in generality, however, as simply across behaviors, the neural data distribution will begin appearing nonlinear~\citep{fortunato2024nonlinear}. It is thus through this systems lens that I most expect BCIs to benefit from deep learning.



% =========================
% Aim 1
% =========================
\chapter{Aim 1: Large-scale pretraining for intracortical neural datasets}

\section{Summary and Significance}
Deep learning’s greatest successes have depended on exploiting large and varied datasets. We perform two scaling studies on Transformer pretraining for motor cortical decoding, measuring returns on increased pretraining across sessions, subjects, and tasks. Cross-session data scales nearly as well as same-day data, while cross-subject and cross-task data yield positive but attenuated returns. Pretraining on $\sim$2000 hours of pooled activity continues to help, but benefits decline rapidly as downstream data grows (converging near $\sim$90 minutes of task data). Thus, pretraining accelerates calibration but does not eliminate the need for ongoing data collection.

\paragraph{Papers.} Ye et~al., ``Neural Data Transformer 2''; Ye et~al., ``A Generalist Intracortical Motor Decoder.''

\section{Approach}
We study pretraining (large, loosely related datasets) and fine-tuning (small, closely related data) while varying data volume, diversity, model size, and compute. Evaluation uses fixed held-out contiguous blocks per dataset. The NDT2 and NDT3 architectures tokenize spikes in 20\,ms bins and spatial patches; NDT2 follows a masked prediction objective, while NDT3 is autoregressive and supports variable behavioral dimensionality.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.5\linewidth]{ch2_ndt_models.png}
  \caption{NDT2 and NDT3 both take input neural data and output neural data and behavior predictions. Both models tokenize neural data in time with 20ms timebins and in space by dividing the population activity into subsets of fixed size (32 in this figure). NDT2 emits one behavior token for prediction at each timestep, while NDT3 emits one behavior token per behavior dimension and timestep, which enables streamlined prediction of behavioral data of varied dimensionality. NDT2, inspired by a Masked Autoencoder design [He], masks out a fraction of neural token inputs and only predicts this fraction. NDT3 adopts the autoregressive modeling framework and allows prediction of all neural tokens conditioned on neural tokens from previous timesteps.}
  \label{fig:ndt_models}
\end{figure}

\section{Results}
NDT2 demonstrates transfer across sessions/subjects/tasks via population patching, Pareto-dominating from-scratch models in zero-shot and with small supervised/unsupervised calibration. NDT3 scales pretraining to 2000\,h and confirms: (i) pretraining helps broadly up to $\sim$90\,min of downstream data, after which from-scratch models catch up; (ii) larger pretraining datasets and models yield better averages.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.5\linewidth]{ch2_ndt2_results.png}
  \caption{A. NDT2 decoding of monkey reach velocity scales with increasing pretraining data from different sessions, subjects, and behavioral tasks. The pretraining abscissa for the single-session curve indicates the total training data available to the model. For the order curves, the abscissa indicates the pretraining data scale. These pretrained models fine-tune to the target session with 100 trials of data. B. Pretrained multisession models can be deployed on new sessions for immediate zero-shot performance. They can also be tuned either through supervised or unsupervised objectives to improve performance, which pareto-dominates performance achieved by training models from scratch.}
  \label{fig:ndt2_results}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.5\linewidth]{ch2_ndt3_summary.png}
  \caption{Two summary views of all evaluations conducted on NDT3 models. Left: When evaluations are organized by downstream data scale (Minutes of Task Data), a pretrained model is better than or equal to non-pretrained models and a linear baseline at all data scales. However, the non-pretrained NDT3 model matches the pretrained model when downstream task data is sufficiently large, here at 90 minutes. Right: Collapsing all evaluations into a single average, we see that scaling pretraining dataset size and model size improves summary performance.}
  \label{fig:ndt3_summary}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.5\linewidth]{ch2_trialized.png}
  \caption{Models are evaluated on a human open-loop cursor dataset prepared in two ways. Trialized training receives inputs according to trial boundaries, varying from 2-4 seconds in length. Continuous training receives random 1 second snippets (that can cross trial boundaries). Trialized evaluation matches trialized training, and continuous evaluation is done by streaming up to 1 second of history. Downward arrows indicate points below 0.0. Continuously trained models perform well in both evaluation settings, while models trained on trialized data fail in continuous evaluation.}
  \label{fig:trialized}
\end{figure}

% =========================
% Aim 2
% =========================
\chapter{Aim 2: Pretrained deep networks enable continuous and scalable upper-limb neuroprosthetic control}

\section{Summary and Significance}
Implanted BCIs can decode diverse upper-limb behaviors, but current decoders need substantial daily calibration and underperform able-bodied control. We propose NDT3-based controllers accumulating calibration across days to deliver robust 7--9\,DoF control in up to two participants, and to demonstrate scalability to additional hand DoF without architectural changes.

\section{Approach}
Key ideas: (i) shift from daily retraining to a large initial calibration plus brief daily adaptation; (ii) extend to higher DoF, starting with thumb and grouped fingers. Calibration uses virtual reach--grasp--carry sequences at multiple speeds; training uses robust objectives (e.g., Soft-DTW). Evaluation includes ARAT and timed object transfer, plus virtual metrics (path efficiency, phase-wise performance).

\section{Results \& Remaining Work}
Pilots: NDT3 matches linear decoders for 2D cursor control; ReFIT improves linear speed more than NDT, suggesting gain/label-noise sensitivity. In 4D Mujoco control, linear decoders degrade under unconstrained DoF due to instability, whereas NDT maintains performance via implicit DoF isolation. Multiday adaptation boosts success and completion time, supporting feasibility for continuous 7D control.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.5\linewidth]{ch3_cursor_control.png}
  \caption{A. OLE and NDT brain-control trajectories in one human participant. B. NDT matches linear model performance for 2D cursor control when all models are trained on an open loop calibration block. Fitting the large NDT model is preferred. B. After closed loop tuning, linear control steadily improves, but NDT speed does not. Gain can be increased to keep NDT at pace.}
  \label{fig:cursor}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.5\linewidth]{ch3_mujoco_results.png}
  \caption{A. Orochi linear decoder compared against NDT DNN decoder for Mujoco 4D FBC Sequenced movement trials. Error bars show standard deviation across trials. Evaluations are conducted in constrained and unconstarined settings. Constrained evaluations only allow one of arm translation, wrist rotation, or hand grasp to be active at a time. B. Multiday NDT decoders achieve high success and faster completion times relative to decoders trained from scratch.}
  \label{fig:mujoco}
\end{figure}

% =========================
% Aim 3
% =========================
\chapter{Aim 3: Modeling the neural response to intracortical microstimulation}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.5\linewidth]{ch4_delete_schema.png}
  \caption{DELETE method schematic overview.}
  \label{fig:delete_schema}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.5\linewidth]{ch4_third_modality.png}
  \caption{Third modality analysis for ICMS modeling.}
  \label{fig:third_modality}
\end{figure}

\section{Summary and Significance}
Sensory feedback is integral to dexterous control. We decompose the stimulation problem into modeling (i) stimulation$\to$local neural response and (ii) local response$\to$percept. We focus here on (i), introducing DELETE (Denoising Electrical Events with a Transformer Encoder) for artifact removal and using transfer-learning assays to taxonomize ICMS responses across temporal patterns and channels.

\section{Approach}
\subsection*{Recovering the neural response with DELETE}
DELETE reconstructs broadband multichannel activity to estimate and subtract artifacts. Constraints (short windows, point-estimate loss, broad training) reduce the risk of erasing spikes. We benchmark DELETE against PCA/linear baselines and analyze as a generic denoiser on non-ICMS data.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.5\linewidth]{ch4_delete_peristim.png}
  \caption{A. Left: A sample broadband recording from a channel during a stimulation trial. The displayed channel is on the electrode array that is stimulated. Right: Spike waveforms recovered from the broadband activity both prior to stimulation onset and in the artifacted peri-stimulation period. B. To summarize waveform recovery, we compute channel SNR as a ratio of peak waveform amplitude against background noise amplitude. The color of each dot indicates the physical array the channel is on. We expect physiological waveform SNRs to be conserved through stimulation, so high correlation of quiet period and peri-stim SNR provides a heuristic for good de-artifacting. Dashed red lines indicate the 4.5x background noise threshold we use to determine spike presence. C. We evaluate model sensitivity by injecting synthetic spikes into the broadband activity and evaluating whether they are recovered. The colored curves differ in the precise waveform injected, which were either recorded and extracted from the data or simulated. Horizontal lines indicate the noise ceiling computed as the recovery rate of spikes injected outside of stimulation periods.}
  \label{fig:delete_peristim}
\end{figure}

\subsection*{Taxonomizing passive ICMS responses}
We collect single- and multi-channel passive ICMS datasets including random-amplitude Poisson (RAP) and fixed-train stimuli, and use RNN/Transformer models to test generalization across time patterns, channels, and days.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.5\linewidth]{ch4_delete_generic.png}
  \caption{A. Top: Butteworth filter extracted spiking activity from a minute of resting state recordings. Inset shows putative movement-induced artifact. Bottom: The same data pre-filtered by DELETE, inset no longer shows correlated firing across channels. B. Peak voltages of waveforms extracted by DELETE and a standard Butterworth filter are compared. There is high correlation, but DELETE peaks saturate by 100uV. C. Firing rates are determined by convolving a 50ms Gaussian kernel against Butterworth or DELETE filtered spiking activity. These per-channel firing rates are correlated across a number of different channels and datasets. Color of dots indicate datasets. High SNR channels correlate well.}
  \label{fig:delete_generic}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.5\linewidth]{ch4_icms_taxonomy.png}
  \caption{A. Example raster plots to stimulation on a single channel (40). Modulated responses are visible both on the stimulated array (bottom two rows) and another sensory array (top two rows). Firing rates as inferred by computing PSTH and RNN models are given on the right. B. Example analysis testing generalization of RNN models to novel single channel stimulation trains. In these plots, models are first trained on either random amplitude Possion (RAP) or fixed frequency and amplitude trains (Fixed). They are then gradually exposed to increasing levels (\% novel condition shown) of a new set of ICMS again from either RAP or fixed stimuli (Test condition). The flat dotted line marks the max performance achieved by any in-distribution model. The closer the other curves are to this flat line, the better the model's generalization to new stimuli. C. Here, we train one model on one type of RAP ICMS and assess its generalization to 3 stimulation conditions from either the same or different experimental session. D. We conduct a brief scaled pretraining analysis. We vary the pretraining scale (Trials seen) and subsequent fine-tuning scale (Calibration), and evaluate on a new session. Session identity is either not modeled (Session Embed None) or modeled with a linear readin layer (Linear). The reference line shows session performance using only 500 calibration trials from the evaluation dataset. Most pretrained models exceed this level, suggesting positive transfer.}
  \label{fig:icms_taxonomy}
\end{figure}

\section{Results \& Remaining Work}
DELETE outperforms baselines for peri-stim recovery and preserves high-SNR spike statistics on non-ICMS data. ICMS taxonomy suggests temporal-pattern generalization within-channel is good (RAP$\to$RAP), but cross-channel transfer is weak; multiday models benefit from increased training data but can plateau or regress with RNNs, motivating NDT-style multisession models. Remaining work: finalize DELETE benchmarking suite; ground recovered response statistics physiologically; expand taxonomy across participants/areas or toward inverse-modeling/percept decoding.

% =========================
% Schedule
% =========================
\chapter{Schedule}
I began my doctoral research with a stimulation focus (Aim 3), but put it on hiatus to study how we might aggregate neural datasets (Aim 1). My remaining schedule begins with data collection for NDT-control experiments (Aim 2). As those experiments wind down I expect to be able to focus on writing those results up while running analysis and writeup for Aim 3. Note I expect Aim 3 to produce two publications, one on the artifact removal work and one on the ICMS response taxonomy work.

\begin{figure}[h]
  \centering
  \includegraphics[width=1.0\linewidth]{ch5_schedule_gantt.png}
  \caption{Gantt chart overview of project priorities throughout the PhD.}
  \label{fig:schedule}
\end{figure}

% =========================
% References
% =========================
\cleardoublepage
\printbibliography

\end{document}
